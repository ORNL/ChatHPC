# website/_data/publications.yml
- title: "ChatHPC: Building the Foundations for a Productive and Trustworthy AI-Assisted HPC Ecosystem"
  venue: "SC '25: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis"
  year: 2025
  badge: "SC25"
  badge_class: "pub-badge--dark"   # optional, for styling
  authors:
    - "Pedro Valero Lara"
    - "Aaron Young"
    - "Jeffrey S. Vetter"
    - "Zheming Jin"
    - "Swaroop Pophale"
    - "Mohammad Alaul Haque Monil"
    - "Keita Teranishi"
    - "William F. Godoy"
  links:
    doi: "https://doi.org/10.1145/3712285.3759787"
    pdf: "https://dl.acm.org/doi/pdf/10.1145/3712285.3759787"
    slides: "/assets/pdf/ChatHPC-SC25.pdf"
  bibtex: |
    @inproceedings{10.1145/3712285.3759787,
      author = {Valero Lara, Pedro and Young, Aaron and Vetter, Jeffrey S. and Jin, Zheming and Pophale, Swaroop and Alaul Haque Monil, Mohammad and Teranishi, Keita and Godoy, William F.},
      title = {ChatHPC: Building the Foundations for a Productive and Trustworthy AI-Assisted HPC Ecosystem},
      year = {2025},
      isbn = {9798400714665},
      publisher = {Association for Computing Machinery},
      address = {New York, NY, USA},
      url = {https://doi.org/10.1145/3712285.3759787},
      doi = {10.1145/3712285.3759787},
      abstract = {ChatHPC democratizes large language models for the high-performance computing (HPC) community by providing the infrastructure, ecosystem, and knowledge needed to apply modern generative AI technologies to rapidly create specific capabilities for critical HPC components while using relatively modest computational resources. Our divide-and-conquer approach focuses on creating a collection of reliable, highly specialized, and optimized AI assistants for HPC based on the cost-effective and fast Code Llama fine-tuning processes and expert supervision. We target major components of the HPC software stack, including programming models, runtimes, I/O, tooling, and math libraries. Thanks to AI, ChatHPC provides a more productive HPC ecosystem by boosting important tasks related to portability, parallelization, optimization, scalability, and instrumentation, among others. With relatively small datasets (on the order of KB), the AI assistants, which are created in a few minutes by using one node with two NVIDIA H100 GPUs and the ChatHPC library, can create new capabilities with Meta’s 7-billion parameter Code Llama base model to produce high-quality software with a level of trustworthiness of up to 90\% higher than the 1.8-trillion parameter OpenAI ChatGPT-4o model for critical programming tasks in the HPC software stack.},
      booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
      pages = {458–474},
      numpages = {17},
      keywords = {Large Language Models, Productivity, Trustworthiness, High Performance Computing.},
      location = {
      },
      series = {SC '25}
    }

- title: "ChatMPI: LLM-Driven MPI Code Generation for HPC Workloads"
  venue: "SCA/HPCAsia '26: Proceedings of the Supercomputing Asia and International Conference on High Performance Computing in Asia Pacific Region"
  year: 2026
  badge: "SCA/HPCAsia"
  authors:
    - "Pedro Valero-Lara"
    - "Aaron Young"
    - "Thomas Naughton III"
    - "Christian Engelmann"
    - "Al Geist"
    - "Jeffrey S. Vetter"
    - "Keita Teranishi"
    - "William F. Godoy"
  links:
    doi: "https://doi.org/10.1145/3773656.3773659"
    pdf: "https://dl.acm.org/doi/pdf/10.1145/3773656.3773659"
    slides: "/assets/pdf/ChatMPI-SCA-HPCAsia26.pdf"
  bibtex: |
    @inproceedings{10.1145/3773656.3773659,
      author = {Valero-Lara, Pedro and Young, Aaron and Naughton III, Thomas and Engelmann, Christian and Geist, Al and Vetter, Jeffrey S. and Teranishi, Keita and Godoy, William F.},
      title = {ChatMPI: LLM-Driven MPI Code Generation for HPC Workloads},
      year = {2026},
      isbn = {9798400720673},
      publisher = {Association for Computing Machinery},
      address = {New York, NY, USA},
      url = {https://doi.org/10.1145/3773656.3773659},
      doi = {10.1145/3773656.3773659},
      abstract = {The Message Passing Interface (MPI) standard plays a crucial role in enabling scientific applications for parallel computing and is an essential component in high-performance computing (HPC). However, implementing MPI code manually—especially applying a proper domain decomposition and communication pattern—is a challenging and error-prone task. We present ChatMPI, an AI assistant for MPI parallelization of sequential C codes. In our analysis, we focus on testing six essential HPC workloads, which are based on Basic Linear Algebra Subprograms levels 1, 2, and 3 as well as sparse, stencil, and iterative operations. We analyze the process of creating ChatMPI by using the ChatHPC library. This lightweight large language model (LLM)–based infrastructure enables HPC experts to efficiently create and supervise trustworthy AI capabilities for critical HPC software tasks. We study the data required for training (fine-tuning) ChatMPI to generate parallel codes that not only use MPI syntax correctly but also apply HPC techniques to reduce memory communication and maximize performance by using proper work decomposition. With a relatively small training dataset composed of a few dozen prompts and fewer than 15 minutes of fine-tuning on one node equipped with two NVIDIA H100 GPUs, ChatMPI elevates trustworthiness for MPI code generation of current LLMs (e.g., Code Llama, ChatGPT-4o and ChatGPT 5). Additionally, we evaluate the performance of the MPI codes generated by ChatMPI in comparison with the ones generated by ChatGPT-4o and ChatGPT-5. The codes generated by ChatMPI provide up to a 4 \texttimes{} boost in performance by using better problem decomposition, communication patterns, and HPC techniques (e.g., communication avoiding).},
      booktitle = {Proceedings of the Supercomputing Asia and International Conference on High Performance Computing in Asia Pacific Region},
      pages = {19–30},
      numpages = {12},
      keywords = {ChatHPC, AI, LLM, MPI, HPC},
      location = {
      },
      series = {SCA/HPCAsia '26}
    }
